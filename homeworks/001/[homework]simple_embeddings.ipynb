{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc8iHXIVwDwj"
   },
   "source": [
    "***Some parts of the notebook are almost the copy of [ mmta-team course](https://github.com/mmta-team/mmta_fall_2020). Special thanks to mmta-team for making them publicly available. [Original notebook](https://github.com/mmta-team/mmta_fall_2020/blob/master/tasks/01_word_embeddings/task_word_embeddings.ipynb).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D0wm5jt6j0U"
   },
   "source": [
    "<b> Прочитайте семинар, пожалуйста, для успешного выполнения домашнего задания. В конце ноутка напишите свой вывод. Работа без вывода оценивается ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIWqBuEa6j0b"
   },
   "source": [
    "## Задача поиска схожих по смыслу предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkwMPLA6j0g"
   },
   "source": [
    "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNRXIEfu5a3Q"
   },
   "source": [
    "До этого в курсе не было речи про задачу ранжировния, поэтому введем математическую формулировку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9FwWNd5a3S"
   },
   "source": [
    "## Задача ранжирования(Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwY9-f75a3T"
   },
   "source": [
    "* $X$ - множество объектов\n",
    "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
    "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
    "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
    "### Задача:\n",
    "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
    "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG2IGBsh5a3U"
   },
   "source": [
    "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQk_rolFwT_h"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUe1PGXn6j0l"
   },
   "source": [
    "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
    "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:46.591149Z",
     "start_time": "2025-09-26T21:59:46.574468Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYkI54Y-rk7a",
    "outputId": "79e4b5e0-9e6b-47b9-e41d-6361ba3b1e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to SO_vectors_200.bin\n"
     ]
    }
   ],
   "source": [
    "import requests, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1\"\n",
    "out_path = \"SO_vectors_200.bin\"\n",
    "\n",
    "if not Path(out_path).exists():\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "print(\"Saved to\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:50.769630Z",
     "start_time": "2025-09-26T21:59:46.617326Z"
    },
    "id": "O8YJTOYv6j0s"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIcT_g-C6j1E"
   },
   "source": [
    "#### Как пользоваться этими векторами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWO5SPDY6j1G"
   },
   "source": [
    "Посмотрим на примере одного слова, что из себя представляет embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:50.818170Z",
     "start_time": "2025-09-26T21:59:50.816386Z"
    },
    "id": "KeSBlQfk6j1J",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (200,)\n"
     ]
    }
   ],
   "source": [
    "word = 'dog'\n",
    "if word in wv_embeddings:\n",
    "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:50.862712Z",
     "start_time": "2025-09-26T21:59:50.860884Z"
    },
    "id": "T4Eq-D1qxpMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of words: 1787145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT6NTCys6j1Q"
   },
   "source": [
    "Найдем наиболее близкие слова к слову `dog`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "#### ***Вопрос 1:***\n",
    "* Входит ли слово `cat` в топ-5 близких слов к слову `dog`? Какое место оно занимает?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.113591Z",
     "start_time": "2025-09-26T21:59:50.905333Z"
    },
    "id": "nYwVz0xG6j1U",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cat' не входит в топ-5 ближайших слов к 'cat'.\n"
     ]
    }
   ],
   "source": [
    "topn = 5\n",
    "target = 'cat'\n",
    "\n",
    "similar = wv_embeddings.most_similar(word, topn=topn)\n",
    "ranks = [w for w, _ in similar]\n",
    "if target in ranks:\n",
    "    print(f\"Да, '{target}' в топ-{topn}. Место: {ranks.index(target) + 1}\")\n",
    "else:\n",
    "    print(f\"'{target}' не входит в топ-{topn} ближайших слов к '{target}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wu7O43AY5jH"
   },
   "source": [
    "***Ваш ответ:*** 'cat' не входит в топ-5 ближайших слов к 'dog'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai48-5vv6j1d"
   },
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.126009Z",
     "start_time": "2025-09-26T21:59:51.120566Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Tokenizer(ABC):\n",
    "    @abstractmethod\n",
    "    def tokenize(self, text:str)->list[str]: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.362458Z",
     "start_time": "2025-09-26T21:59:51.164936Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def question_to_vec(query:str, embeddings:KeyedVectors, tokenizer_engine:Tokenizer, dim:int=200)->np.ndarray:\n",
    "    \"\"\"\n",
    "        query: строка\n",
    "        embeddings: наше векторное представление\n",
    "        tokenizer_engine: токенайзер\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "\n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\"\n",
    "    if embeddings.vector_size != dim:\n",
    "        raise ValueError(\"wrong dim\")\n",
    "\n",
    "    tokens = tokenizer_engine.tokenize(query)\n",
    "    summ = np.zeros(dim, dtype=np.float32)\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in embeddings:\n",
    "            vec = embeddings[token]\n",
    "            summ += vec\n",
    "            count = count + 1\n",
    "\n",
    "    if count > 0:\n",
    "        summ = summ / count\n",
    "\n",
    "    return summ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Вопрос 2:***\n",
    "\n",
    "* Какая третья (с индексом 2) компонента вектора предложения `I love neural networks` (округлите до 2 знаков после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.366692Z",
     "start_time": "2025-09-26T21:59:51.365185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.29\n"
     ]
    }
   ],
   "source": [
    "# Предложение\n",
    "question = \"I love neural networks\"\n",
    "\n",
    "print(f\"{question_to_vec(question, wv_embeddings, tokenizer)[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями.\n",
    "\n",
    "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
    "* $\\begin{equation*}\n",
    "[x < 0 ] \\equiv\n",
    " \\begin{cases}\n",
    "   1, &x < 0\\\\\n",
    "   0, &x \\geq 0\n",
    " \\end{cases}\n",
    "\\end{equation*}$ - индикаторная функция\n",
    "* $q_i$ - $i$-ый вопрос\n",
    "* $q_i^{'}$ - его дубликат\n",
    "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
    "\n",
    "Hits@K  измеряет долю вопросов, для которых правильный ответ попал в топ-K позиций среди отранжированных кандидатов.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
    "С такой метрикой модель штрафуется за большой ранк корректного ответа.\n",
    "\n",
    "DCG@K  измеряет качество ранжирования, учитывая не только факт наличия правильного ответа в топ-K, но и ***его точную позицию***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера.\n",
    "Пусть\n",
    "* $N = 1$, $R = 3$\n",
    "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
    "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
    "\n",
    "Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. \"Как изучить с++?\"\n",
    "2. <font color='red'>\"Что такое язык python?\"</font>\n",
    "3. \"Хочу учить Java\"\n",
    "4. \"Не понимаю Tensorflow\"\n",
    "\n",
    "$\\Rightarrow rank\\_q_i^{'} = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1]$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_1} \\leq 1 $: ***условие неверно***.\n",
    "\n",
    "Следовательно, $[\\text{rank}_{q'_1} \\leq 1] = 0$.\n",
    "\n",
    "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_1} \\leq 4 $: ***условие верно***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Вопрос 3***:\n",
    "* Вычислите `DCG@10`, если $rank\\_q_i^{'} = 9$(округлите до одного знака после запятой)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Более сложный пример оценок\n",
    "\n",
    "Рассмотрим пример с $ N > 1 $, где $ N = 3 $ (три вопроса) и для каждого вопроса заданы позиции их дубликатов. Вычислим метрики **Hits@K** для разных значений $ K $.\n",
    "\n",
    "---\n",
    "\n",
    "- $ N = 3 $: Три вопроса ($ q_1, q_2, q_3 $).\n",
    "- Для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
    "  - $ \\text{rank}_{q'_1} = 2 $,\n",
    "  - $ \\text{rank}_{q'_2} = 5 $,\n",
    "  - $ \\text{rank}_{q'_3} = 1 $.\n",
    "\n",
    "Мы будем вычислять **Hits@K** для $ K = 1, 5 $.\n",
    "\n",
    "---\n",
    "\n",
    "**Для $ K = 1 $:**\n",
    "\n",
    "Подставим значения:\n",
    "$$\n",
    "\\text{Hits@1} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 1] + [\\text{rank}_{q'_2} \\leq 1] + [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
    "$$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
    "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
    "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
    "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
    "\n",
    "Сумма:\n",
    "$$\n",
    "\\text{Hits@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Hits@1} = \\frac{1}{3}}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Для $ K = 5 $:**\n",
    "\n",
    "Подставим значения:\n",
    "$$\n",
    "\\text{Hits@5} = \\frac{1}{3} \\cdot \\left( [\\text{rank}_{q'_1} \\leq 5] + [\\text{rank}_{q'_2} \\leq 5] + [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
    "$$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
    "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
    "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
    "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
    "\n",
    "Сумма:\n",
    "$$\n",
    "\\text{Hits@5} = \\frac{1}{3} \\cdot (1 + 1 + 1) = 1.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Hits@5} = 1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вычислим метрику **DCG@K** для того же примера, где $ N = 3 $ (три вопроса), и для каждого вопроса известна позиция его дубликата ($ \\text{rank}_{q'_i} $):\n",
    "\n",
    "- $ \\text{rank}_{q'_1} = 2 $,\n",
    "- $ \\text{rank}_{q'_2} = 5 $,\n",
    "- $ \\text{rank}_{q'_3} = 1 $.\n",
    "\n",
    "Мы будем вычислять **DCG@K** для $ K = 1, 5 $.\n",
    "\n",
    "---\n",
    "**Для $ K = 1 $:**\n",
    "Подставим значения:\n",
    "$$\n",
    "\\text{DCG@1} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 1] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 1] \\right).\n",
    "$$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_i} \\leq 1 $ для каждого вопроса:\n",
    "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\not\\leq 1 $ → $ 0 $,\n",
    "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\not\\leq 1 $ → $ 0 $,\n",
    "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 1 $ → $ 1 $.\n",
    "\n",
    "Сумма:\n",
    "$$\n",
    "\\text{DCG@1} = \\frac{1}{3} \\cdot (0 + 0 + 1) = \\frac{1}{3}.\n",
    "$$\n",
    "$$\n",
    "\\boxed{\\text{DCG@1} = \\frac{1}{3}}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Для $ K = 5 $:**\n",
    "Подставим значения:\n",
    "$$\n",
    "\\text{DCG@5} = \\frac{1}{3} \\cdot \\left( \\frac{1}{\\log_2(1 + \\text{rank}_{q'_1})} \\cdot [\\text{rank}_{q'_1} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_2})} \\cdot [\\text{rank}_{q'_2} \\leq 5] + \\frac{1}{\\log_2(1 + \\text{rank}_{q'_3})} \\cdot [\\text{rank}_{q'_3} \\leq 5] \\right).\n",
    "$$\n",
    "\n",
    "Проверяем условие $ \\text{rank}_{q'_i} \\leq 5 $ для каждого вопроса:\n",
    "- $ \\text{rank}_{q'_1} = 2 $ → $ 2 \\leq 5 $ → $ 1 $,\n",
    "- $ \\text{rank}_{q'_2} = 5 $ → $ 5 \\leq 5 $ → $ 1 $,\n",
    "- $ \\text{rank}_{q'_3} = 1 $ → $ 1 \\leq 5 $ → $ 1 $.\n",
    "\n",
    "Сумма:\n",
    "$$\n",
    "\\text{DCG@5} = \\frac{1}{3} \\cdot (0.631 + 0.387 + 1) = \\frac{1}{3} \\cdot 2.018 \\approx 0.673.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{DCG@5} \\approx 0.673}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Вопрос 4:***\n",
    "* Найдите максимум `Hits@47 - DCG@1`?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.411594Z",
     "start_time": "2025-09-26T21:59:51.409304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "rank_q1 = 2\n",
    "rank_q2 = 5\n",
    "rank_q3 = 1\n",
    "\n",
    "ranks = [rank_q1, rank_q2, rank_q3]\n",
    "\n",
    "\n",
    "\n",
    "hits_k = lambda k_val, ranks_val : sum(1 if r_val <= k_val else 0 for r_val in ranks_val) / len(ranks_val)\n",
    "dcg_k = lambda k_val, ranks_val :sum((1 if r_val <= k_val else 0) / (math.log2(1+r_val))  for r_val in ranks_val)/ len(ranks_val)\n",
    "\n",
    "\n",
    "print(hits_k(47, ranks) - dcg_k(1, ranks))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HITS\\_COUNT и DCG\\_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$.\n",
    "\n",
    "$dup\\_ranks$ является списком, который содержит рейтинги дубликатов (их позиции в ранжированном списке).\n",
    "\n",
    "К примеру для <font color='red'>\"Что такое язык python?\"</font> $dup\\_ranks = [2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.455466Z",
     "start_time": "2025-09-26T21:59:51.454224Z"
    }
   },
   "outputs": [],
   "source": [
    "def hits_count(duplicate_ranks, top_k):\n",
    "    \"\"\"\n",
    "        duplicate_ranks: list индексов дубликатов\n",
    "        top_k: пороговое значение для ранга\n",
    "        result: вернуть Hits@k\n",
    "    \"\"\"\n",
    "    # Подсчитываем количество дубликатов, чей ранг <= k\n",
    "\n",
    "    return hits_k(top_k, duplicate_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.499163Z",
     "start_time": "2025-09-26T21:59:51.497530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1 = 0.0\n",
      "Hits@4 = 1.0\n"
     ]
    }
   ],
   "source": [
    "dup_ranks = [2]\n",
    "\n",
    "k = 1\n",
    "hits_value = hits_count(dup_ranks, k)\n",
    "print(f\"Hits@1 = {hits_value}\")\n",
    "\n",
    "k = 4\n",
    "hits_value = hits_count(dup_ranks, k)\n",
    "print(f\"Hits@4 = {hits_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.542855Z",
     "start_time": "2025-09-26T21:59:51.541581Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dcg_score(duplicate_ranks, top_k):\n",
    "    \"\"\"\n",
    "        duplicate_ranks: list индексов дубликатов\n",
    "        top_k: пороговое значение для ранга\n",
    "        result: вернуть DCG@k\n",
    "    \"\"\"\n",
    "\n",
    "    return dcg_k(top_k, duplicate_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.588213Z",
     "start_time": "2025-09-26T21:59:51.586466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@1 = 0.000\n",
      "DCG@4 = 0.631\n"
     ]
    }
   ],
   "source": [
    "# Пример списка позиций дубликатов\n",
    "dup_ranks = [2]\n",
    "\n",
    "# Вычисляем DCG@1\n",
    "dcg_value = dcg_score(dup_ranks, top_k=1)\n",
    "print(f\"DCG@1 = {dcg_value:.3f}\")\n",
    "\n",
    "# Вычисляем DCG@4\n",
    "dcg_value = dcg_score(dup_ranks, top_k=4)\n",
    "print(f\"DCG@4 = {dcg_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.634419Z",
     "start_time": "2025-09-26T21:59:51.632563Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.681045Z",
     "start_time": "2025-09-26T21:59:51.679128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
      "Ваш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
     ]
    }
   ],
   "source": [
    "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
    "\n",
    "# наши кандидаты\n",
    "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                       \"NSLog array description not memory address\",\n",
    "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
    "\n",
    "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
    "dup_ranks = [candidates_ranking[0].index(copy_answers[0]) + 1]\n",
    "\n",
    "# вычисляем метрику для разных k\n",
    "print('Ваш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
    "print('Ваш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.728816Z",
     "start_time": "2025-09-26T21:59:51.723912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HITS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2        3        4\n",
       "HITS  0  1.00000  1.00000  1.00000\n",
       "DCG   0  0.63093  0.63093  0.63093"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct_answers - метрика для разных k\n",
    "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
    "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
    "\n",
    "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
    "\n",
    "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.773703Z",
     "start_time": "2025-09-26T21:59:51.771602Z"
    }
   },
   "outputs": [],
   "source": [
    "out_path = Path(\"stackoverflow_similar_questions.zip\")\n",
    "\n",
    "if not out_path.exists():\n",
    "    import gdown\n",
    "    import zipfile\n",
    "\n",
    "    gdown.download(\n",
    "        id=\"1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_\",\n",
    "        output=str(out_path.resolve()),\n",
    "        quiet=False\n",
    "    )\n",
    "    Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(out_path, \"r\") as zf:\n",
    "        zf.extractall(path=\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:51.818448Z",
     "start_time": "2025-09-26T21:59:51.816681Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        for l in file:\n",
    "            data.append(l.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам понадобиться только файл validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.141482Z",
     "start_time": "2025-09-26T21:59:51.862576Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_data = read_corpus('./data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.147851Z",
     "start_time": "2025-09-26T21:59:52.145899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер нескольких первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.194385Z",
     "start_time": "2025-09-26T21:59:52.192575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "2 1001\n",
      "3 1001\n",
      "4 1001\n",
      "5 1001\n",
      "6 1001\n",
      "7 1001\n",
      "8 1001\n",
      "9 1001\n",
      "10 1001\n",
      "11 1001\n",
      "12 1001\n",
      "13 1001\n",
      "14 1001\n",
      "15 1001\n",
      "16 1001\n",
      "17 1001\n",
      "18 1001\n",
      "19 1001\n",
      "20 1001\n",
      "21 1001\n",
      "22 1001\n",
      "23 1001\n",
      "24 1001\n",
      "25 1001\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(i + 1, len(validation_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранжирование без обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список **[(2, c), (0, a), (1, b)]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.239424Z",
     "start_time": "2025-09-26T21:59:52.237966Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.289011Z",
     "start_time": "2025-09-26T21:59:52.284392Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def rank_candidates(query:str, candidate_texts:list[str], embeddings:KeyedVectors, tokenizer_engine:Tokenizer, dim:int=200, normalize:bool=True)->list[tuple[int, str]]:\n",
    "    \"\"\"\n",
    "        query: строка\n",
    "        candidate_texts: массив строк(кандидатов) [a, b, c]\n",
    "        embeddings: наше векторное представление\n",
    "        tokenizer_engine: токенайзер\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "\n",
    "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
    "    \"\"\"\n",
    "    if embeddings.vector_size != dim:\n",
    "        raise ValueError(\"wrong dim\")\n",
    "    query = query.lower() if normalize else query\n",
    "    question_vec = question_to_vec(query,embeddings, tokenizer_engine, dim ).reshape(1, -1)\n",
    "    answers_vec = np.vstack([question_to_vec(c.lower() if normalize else c, embeddings, tokenizer_engine, dim) for c in candidate_texts])\n",
    "    similarity = cosine_similarity(question_vec,answers_vec)[0]\n",
    "    similarity_sort =  sorted({(idx, candidate_texts[idx]): sim for idx, sim in enumerate(similarity)}.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    result =  list(OrderedDict(similarity_sort).keys())\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.335174Z",
     "start_time": "2025-09-26T21:59:52.333471Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = ['converting string to list', 'Sending array via Ajax fails']\n",
    "\n",
    "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
    "               'C# create cookie from string and send it',\n",
    "               'How to use jQuery AJAX for an outside domain?'],\n",
    "\n",
    "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
    "               'WPF- How to update the changes in list item of a list',\n",
    "               'select2 not displaying search results']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты работы с приведением слов к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.379533Z",
     "start_time": "2025-09-26T21:59:52.377274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'C# create cookie from string and send it'), (0, 'Convert Google results object (pure js) to Python object'), (2, 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "[(0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results'), (1, 'WPF- How to update the changes in list item of a list')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, q_candidates in zip(questions, candidates):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
    "        print(ranks)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты работы без  приведением слов к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.423179Z",
     "start_time": "2025-09-26T21:59:52.421341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'C# create cookie from string and send it'), (0, 'Convert Google results object (pure js) to Python object'), (2, 'How to use jQuery AJAX for an outside domain?')]\n",
      "\n",
      "[(1, 'WPF- How to update the changes in list item of a list'), (0, 'Getting all list items of an unordered list in PHP'), (2, 'select2 not displaying search results')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, q_candidates in zip(questions, candidates):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer, normalize = False)\n",
    "        print(ranks)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для первого экперимента вы можете полностью сравнить ваши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.468149Z",
     "start_time": "2025-09-26T21:59:52.466746Z"
    }
   },
   "outputs": [],
   "source": [
    "# должно вывести\n",
    "results = [[(1, 'C# create cookie from string and send it'),\n",
    "            (0, 'Convert Google results object (pure js) to Python object'),\n",
    "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "           [(0, 'Getting all list items of an unordered list in PHP'),\n",
    "            (2, 'select2 not displaying search results'),\n",
    "            (1, 'WPF- How to update the changes in list item of a list')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность начальных индексов вы должны получить `для эксперимента 1`  1, 0, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Вопрос 5:***\n",
    "* Какую последовательность начальных индексов вы получили `для эксперимента 2`(перечисление без запятой и пробелов, например, `102` для первого эксперимента?\n",
    "\n",
    "Ответ: `021`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Можете взять для validation 1000 примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:59:52.562261Z",
     "start_time": "2025-09-26T21:59:52.510219Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "def build_wv_ranking(data, embeddings:KeyedVectors, tokenizer_engine:Tokenizer, limit:Optional[int] = None, normalize:bool=True):\n",
    "    wv_ranking_result = []\n",
    "    for idx, item in enumerate(tqdm(data)):\n",
    "        if limit is not None and idx == limit:\n",
    "            break\n",
    "        query, *examples = item\n",
    "        ranks_result = rank_candidates(query, examples, embeddings, tokenizer_engine, normalize=normalize)\n",
    "        wv_ranking_result.append([rank[0] for rank in ranks_result].index(0) + 1)\n",
    "\n",
    "    return wv_ranking_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T22:00:40.852445Z",
     "start_time": "2025-09-26T21:59:52.566204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7122ef2e8c684907aaa9822d5b90d966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "jetTransient": {
      "display_id": null
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8635384c285d4c90987ddc95e4adf5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "jetTransient": {
      "display_id": null
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.407 | Hits@   1: 0.407\n",
      "DCG@   5: 0.498 | Hits@   5: 0.578\n",
      "DCG@  10: 0.522 | Hits@  10: 0.651\n",
      "DCG@ 100: 0.566 | Hits@ 100: 0.868\n",
      "DCG@ 500: 0.580 | Hits@ 500: 0.975\n",
      "DCG@1000: 0.583 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "wv_ranking = build_wv_ranking(validation_data, wv_embeddings, tokenizer)\n",
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из формул выше можно понять, что\n",
    "\n",
    "- $ \\text{Hits@K} $ **монотонно неубывающая функция** $ K $, которая стремится к 1 при $ K \\to \\infty $.\n",
    "\n",
    "- $ \\text{DCG@K} $ **монотонно неубывающая функция** $ K $, но рост замедляется с увеличением $ K $ из-за убывания веса $ \\frac{1}{\\log_2(1 + \\text{rank}_{q'_i})} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги, обученные на корпусе похожих вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T22:00:42.069235Z",
     "start_time": "2025-09-26T22:00:40.904158Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = read_corpus('./data/train.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшите качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберите размер window. Объясните свой выбор.\n",
    "\n",
    "***Рассмотрим подробнее*** данное склеивание.\n",
    "\n",
    "1. Каждая строка из train_data разбивается на вопрос (question) и список кандидатов.\n",
    "\n",
    "2. Для каждого кандидата вопрос склеивается с ним в одну строку.\n",
    "\n",
    "3. Склеенная строка (combined_text) токенизируется, и полученный список токенов добавляется в общий корпус (corpus).\n",
    "\n",
    "***Пример***\n",
    "\n",
    "    Вопрос: \"What is Python?\"\n",
    "    Кандидаты: [\"Python is a programming language\", \"Java is another language\"]\n",
    "    Склеенные строки:\n",
    "        \"What is Python? Python is a programming language\"\n",
    "        \"What is Python? Java is another language\"\n",
    "         \n",
    "    Токенизированные списки:\n",
    "        ['what', 'is', 'python', 'python', 'is', 'a', 'programming', 'language']\n",
    "        ['what', 'is', 'python', 'java', 'is', 'another', 'language']\n",
    "         \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T22:00:42.119407Z",
     "start_time": "2025-09-26T22:00:42.117387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Determine if the device is a smartphone or tablet?',\n",
       " 'Change imageView params in all cards together']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[111258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T22:00:42.165245Z",
     "start_time": "2025-09-26T22:00:42.163348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Создаем общий корпус текстов\n",
    "def build_corpus(data:list[list[str]], tokenizer_engine:Tokenizer, normalize:bool=True):\n",
    "    corpus_result = []\n",
    "    for item in data:\n",
    "        if len(item) <= 1:\n",
    "            continue\n",
    "        query  = item[0]\n",
    "        for examples in item[1:]:\n",
    "            concat_text = f\"{query} {examples}\"\n",
    "            corpus_result.append(tokenizer_engine.tokenize(concat_text.lower() if normalize else concat_text))\n",
    "    return corpus_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T22:00:46.167623Z",
     "start_time": "2025-09-26T22:00:42.208456Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = build_corpus(train_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T09:27:15.460853Z",
     "start_time": "2025-09-27T09:27:15.245613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens: 105\n"
     ]
    }
   ],
   "source": [
    "max_tokens = -1\n",
    "for t in corpus:\n",
    "    max_tokens = max(max_tokens, len(t))\n",
    "print(f\"max tokens: {max_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем разные варианты для windows и current_count"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# target_params = []\n",
    "# for current_windows in (  10, 105, 150, 180):\n",
    "#     for current_count in (2,3,5,10):\n",
    "#\n",
    "#         embeddings_trained = Word2Vec(\n",
    "#             sentences=corpus,\n",
    "#             vector_size=200,\n",
    "#             window=current_windows,\n",
    "#             min_count=current_count,\n",
    "#             workers=32\n",
    "#         )\n",
    "#         kv = embeddings_trained.wv\n",
    "#         ranks = build_wv_ranking(validation_data, kv, tokenizer, limit=1000, normalize=True)\n",
    "#         hits10 = hits_count(ranks, 10)\n",
    "#         dcg10 = dcg_score(ranks, 10)\n",
    "#         target_params.append({\n",
    "#             \"window\": current_windows,\n",
    "#             \"min_count\": current_count,\n",
    "#             \"Hits@10\": hits10,\n",
    "#             \"DCG@10\": dcg10\n",
    "#         })\n",
    "# target_params.sort(key=lambda x: (x[\"DCG@10\"], x[\"Hits@10\"]), reverse=True)\n",
    "# print(target_params)\n",
    "#"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```[{'window': 180, 'min_count': 10, 'Hits@10': 0.594, 'DCG@10': 0.4836081202584917}, {'window': 180, 'min_count': 5, 'Hits@10': 0.585, 'DCG@10': 0.4767133140367386}, {'window': 150, 'min_count': 10, 'Hits@10': 0.584, 'DCG@10': 0.4759279272314121}, {'window': 150, 'min_count': 5, 'Hits@10': 0.578, 'DCG@10': 0.474757934630991}, {'window': 180, 'min_count': 3, 'Hits@10': 0.575, 'DCG@10': 0.4738912073715378}, {'window': 105, 'min_count': 10, 'Hits@10': 0.582, 'DCG@10': 0.47368553605576336}, {'window': 105, 'min_count': 5, 'Hits@10': 0.581, 'DCG@10': 0.47293118799157347}, {'window': 150, 'min_count': 2, 'Hits@10': 0.576, 'DCG@10': 0.4728387728645323}, {'window': 150, 'min_count': 3, 'Hits@10': 0.579, 'DCG@10': 0.47245360173821804}, {'window': 105, 'min_count': 3, 'Hits@10': 0.578, 'DCG@10': 0.4712054486877369}, {'window': 180, 'min_count': 2, 'Hits@10': 0.576, 'DCG@10': 0.46940530029760863}, {'window': 105, 'min_count': 2, 'Hits@10': 0.573, 'DCG@10': 0.4652144479921041}, {'window': 10, 'min_count': 5, 'Hits@10': 0.523, 'DCG@10': 0.41083477592221823}, {'window': 10, 'min_count': 10, 'Hits@10': 0.521, 'DCG@10': 0.4101784880176292}, {'window': 10, 'min_count': 2, 'Hits@10': 0.522, 'DCG@10': 0.4089606516853269}, {'window': 10, 'min_count': 3, 'Hits@10': 0.524, 'DCG@10': 0.40870873916198075}]```\n",
    "\n",
    "\n",
    "Видно что если выставить аномально высокие значения для window качество немного растет (с DCG@10 с 0.40 до 0.48).\n",
    "Гипотиза почему так происхоидт:\n",
    "\n",
    "При расчете build_wv_ranking не учитывается порядок слов, эмбеддинг для предложения считается как сумма эмбеддинг слов.\n",
    "В итоговый вектор все слова предложения вносят одинаковый вклад.\n",
    "\n",
    "При обучение, с большим значением windows, взаимосвязи ищутся между всеми словами в предложение.\n",
    "Учитываются взаимосвязи между словами, которые стоят в начале и конце предложения.\n",
    "\n",
    "Т.е. мы подталкиваем Word2Vec делать такие эмбеддинг, которые работают лучше, для случая, когда эмбеддинг предложения, это сумма эмбеддинг слов.\n",
    "\n",
    "min_count - отбрасывает токены. Для большого значения window отбрасывания токенов, помогает лучше \"усреднить\" результат, т.е. также адаптирует Word2Vec создавать ембединги, которые лучше подходят для метода когда ембединг предложения = сумме ембедингов слов.\n",
    "\n",
    "Эти улучшения незначительны, но требуют больше ресурсов. Поэтому в практических целях буду использовать window=10 и  min_count=5.\n",
    "В целом от способа, когда целевой эмбединг предложения, это сумма эмбедингов слов, нужно уходить к способу, когда слова содержащие\n",
    "\"смысл\" предложения вносят вклад в эмбединг придложения больше, чем слова с \"низким\" смыслом. При таком способе, большие значения\n",
    "window только бы вредили, т.к. выстраивали взаимосвязи между словами, которые по смыслу не связаны.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embeddings_trained = Word2Vec(\n",
    "    sentences=corpus,        # Корпус токенизированных текстов\n",
    "    vector_size=200,         # Размерность векторов\n",
    "    window=10,                # Размер окна контекста\n",
    "    min_count=5,             # Минимальная частота слов\n",
    "    workers=8                # Количество потоков\n",
    ").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wv_ranking = build_wv_ranking(validation_data, embeddings_trained, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замечание:\n",
    "Решить эту задачу с помощью обучения полноценной нейронной сети будет вам предложено, как часть задания в одной из домашних работ по теме \"Диалоговые системы\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите свой вывод о полученных результатах.\n",
    "* Какой принцип токенизации даёт качество лучше и почему?\n",
    "* Помогает ли нормализация слов?\n",
    "* Какие эмбеддинги лучше справляются с задачей и почему?\n",
    "* Почему получилось плохое качество решения задачи?\n",
    "* Предложите свой подход к решению задачи.\n",
    "\n",
    "## Вывод:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Какой принцип токенизации даёт качество лучше и почему\n",
    "\n",
    "Сделаем проверку для трех токенайзеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class TokenizerRegexp(Tokenizer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        return re.findall(r'\\w+', text)\n",
    "\n",
    "\n",
    "class TokenizerSpacy(Tokenizer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        doc = nlp.make_doc(text)\n",
    "        return [t.text for t in doc]\n",
    "\n",
    "tokenizers = {\n",
    "    \"Корректная обработка - апострофов и сокращений(spaCy)\": TokenizerSpacy(),\n",
    "    \"Последовательности из букв и цифр, отсеивается пунктуация и апострофы(регулярка)\": TokenizerRegexp(),\n",
    "    \"Дробление с учетом знаков пунктуации(WordPunct)\": WordPunctTokenizer(),\n",
    "\n",
    "}\n",
    "\n",
    "for tokenizer_name, current_tokenizer in tokenizers.items():\n",
    "    wv_ranking = build_wv_ranking(validation_data, wv_embeddings, current_tokenizer, limit=1000)\n",
    "    print(tokenizer_name)\n",
    "    for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: Какой принцип токенизации даёт качество лучше и почему?\n",
    "Ответ: Зависит от задачи. Для данной задачи лучшее качество показал токенайзер на простой регулярке. Почему так:\n",
    "- С большой вероятность способ разбиения по регулярке максимально совпадает с способом токенезации который использовался для эмбедингов\n",
    "- В контексте данных с SO пунктуации и апострофы - являются даными создающим шум. Их отбрасывание помогает получать более \"стабильные\" ветокра эмбедингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Помогает ли нормализация слов\n",
    "\n",
    "Возьмем разные способы нормализации слов и проверим на regexp токенайзере\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class TokenizerNormalize(Tokenizer):\n",
    "    def __init__(self, normalizer_func:Callable[[str], str]):\n",
    "        self.normalizer_func = normalizer_func\n",
    "    def tokenize(self, text)-> list[str]:\n",
    "        return re.findall(r'\\w+', self.normalizer_func(text))\n",
    "\n",
    "class TokenizerNormalizeStopWords(Tokenizer):\n",
    "    def __init__(self):\n",
    "        self.stop = set(stopwords.words(\"english\"))\n",
    "    def tokenize(self, text)-> list[str]:\n",
    "        tokens =  re.findall(r'\\w+', text)\n",
    "        return [t for t in tokens if t not in self.stop]\n",
    "\n",
    "class TokenizerRegexList(Tokenizer):\n",
    "    def tokenize(self, text: str) -> list[str]:\n",
    "        return re.findall(r\"[A-Za-z0-9\\+#\\.]+\", text)\n",
    "\n",
    "class TokenizerLemmatizer(Tokenizer):\n",
    "    def __init__(self):\n",
    "        self.stem = SnowballStemmer(\"english\")\n",
    "    def tokenize(self, text: str) -> list[str]:\n",
    "        return [self.stem.stem(t) for t in text.split()]\n",
    "\n",
    "\n",
    "\n",
    "tokenizers = {\n",
    "    \"Лемматизация c SnowballStemmer\": TokenizerLemmatizer(),\n",
    "    \"Без нормализации\": TokenizerNormalize(lambda x: x),\n",
    "    \"Приведение текста к нижнему регистру\": TokenizerNormalize(lambda x: x.lower()),\n",
    "    \"Удаление стоп слов\": TokenizerNormalizeStopWords(),\n",
    "    \"Удаление пунктуации и части символов. Оставляем символы которые встречаются в IT\": TokenizerRegexList()\n",
    "}\n",
    "\n",
    "for tokenizer_name, current_tokenizer in tokenizers.items():\n",
    "    wv_ranking = build_wv_ranking(validation_data, wv_embeddings, current_tokenizer, limit=1000)\n",
    "    print(tokenizer_name)\n",
    "    for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "\n",
    "        print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: Помогает ли нормализация слов?\n",
    "Ответ: Незначительно помогает \"умное\" удаление стоп слов.\n",
    "\n",
    "По остальным результатам:\n",
    "- лематизация - делает сильно хуже, эмбединги явно предобучались без лематизации\n",
    "- без нормализации/приведение к нижнему регистру - по факту одинаково. слов в верхнем регистре мало, они не вносят существенного вклада.\n",
    "- удаление стоп слов, чуть улучшает. т.к меньше шума\n",
    "- удаление стоп слов, но оставление символов которые специфичны для языков программирования. самый хороший результат. но в целом не сильно отличающийся от варианта без нормализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие эмбеддинги лучше справляются с задачей и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С задачей лучше справляются предобученные эмбединги\n",
    "\n",
    "```\n",
    "DCG@   1: 0.408 | Hits@   1: 0.408\n",
    "DCG@   5: 0.498 | Hits@   5: 0.578\n",
    "DCG@  10: 0.522 | Hits@  10: 0.651\n",
    "DCG@ 100: 0.567 | Hits@ 100: 0.868\n",
    "DCG@ 500: 0.580 | Hits@ 500: 0.975\n",
    "DCG@1000: 0.583 | Hits@1000: 1.000\n",
    "```\n",
    "\n",
    "чем эмбединг обученный на нашей выборке\n",
    "\n",
    "```\n",
    "DCG@   1: 0.315 | Hits@   1: 0.315\n",
    "DCG@   5: 0.395 | Hits@   5: 0.469\n",
    "DCG@  10: 0.416 | Hits@  10: 0.532\n",
    "DCG@ 100: 0.466 | Hits@ 100: 0.777\n",
    "DCG@ 500: 0.488 | Hits@ 500: 0.946\n",
    "DCG@1000: 0.493 | Hits@1000: 1.000\n",
    "```\n",
    "\n",
    "Возможные причины:\n",
    "- предобученный эмбединг учились на данных большего объема\n",
    "- лучшая предобработка текста для предобученныех эмбедингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему получилось плохое качество решения задачи?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Основная причина плохого результата в способое получения  эмбединг для предложения:  это сумма векторов слов. Cлова в разном порядке дадут один и тот же вектор. При этом смысл такого предложения может быть координально разным.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.array_equal(\n",
    "    question_to_vec(\"Dog bites man.\", wv_embeddings, tokenizer),\n",
    "    question_to_vec(\"Man bites dog.\", wv_embeddings, tokenizer)\n",
    "):\n",
    "     print(\"Equal\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предложите свой подход к решению задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Улучшить фильтрацию по стоп словам. Лучше учитывать слова специфичные для домена\n",
    "- Если возможен файнтюн для KeyedVectors то пробовать дообучить модель с маленькой скоростью дообучения, на примерах где есть слова специфичные для домена StackOwerflow\n",
    "- Возможно приспбособить tf-idf, что бы создать пары вопрос/ответ только с значимыми словами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emODHztAQUQz"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
